# 오늘 한 것
1. 이상치에 대한 스케일링 실험
2. 모델에 대한 대략적인 튜닝 방법 연구
3. 상관관계가 낮은 원 변수 그냥 삭제해보기

# 결과

1. 이상치가 여전히 잡히고 있었다. 근데 저번에 무라하개 이상치를 다 평준화 시키려다가 오히려 모델의 정확도가 더 떨어자는 것을 발견, 따라서 이걸 이상치 제거가 아니라 스케일링을 통해서 해결하려고 했다. 하지만 결과가 오히려 더 퇴보하고 말았다.

2. xgboost를 기본 모델로 사용하는 것은 어제 합의했고, 약간 튜닝을 해서 모델을 조금 향상시키는 방법을 찾았다.

3. 상관관계 분석을 한 결과다.
![image](https://user-images.githubusercontent.com/95357946/208943067-567e3bc8-76fb-4ca6-95bc-a72bc6f05272.png)

이걸 보면 Delhi east가 상관관계가 정말 낮다고 생각했고, 이걸 제거하고 학습을 돌렸는데, 결과가 더 나빠짐.

따로 원변수를 삭제하는 방법은 쓰지말자.
