{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# STAGE5 하이퍼 파라미터 튜닝"
      ],
      "metadata": {
        "id": "s-4djYmQToDe"
      },
      "id": "s-4djYmQToDe"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 하이퍼 파라미터란?\n",
        "**초매개변수**(hyper parameter)는 학습모델의 학습과정을 제어하기위한 선택사항입니다. \n",
        "\n",
        "예시) 학습률(learning rate), 손실함수(cost function), 미니배치크기(mini-batch size), 가중치 초기화(weight initialization) 등\n",
        "\n",
        "<br/>\n",
        "\n",
        "학습모델마다 다른 초매개변수가 필요하고, 간단한 선형회귀 모델같은 경우는 초매개변수가 없기도 합니다.\n",
        "\n",
        "초매개변수를 어떻게 설정하느냐에 따라 학습시간이 달라지고, 대부분 과적합, 과소적합을 초래합니다. \n",
        "\n",
        "그렇기 때문에 강한 모델을 위한 **초매개변수 최적화**는 필수적입니다.\n",
        "\n",
        "<br/>\n",
        "\n",
        "하지만 초매개변수 최적화는 휴리스틱(heuristic)한 방법이나\n",
        "\n",
        "경험상 통용되는(rules of thumb)방법에 의해 결정되는 경우가 많습니다. \n",
        "\n",
        "😓 \"학습모델을 처음 사용하는 데... 어떡하나요?\"\n",
        "\n",
        "여러 초매개변수를 바꾸며 학습하는 많은 시도를 해야합니다!\n",
        "\n",
        "<br/>\n",
        " \n",
        "저희 팀은 여러 시도를 도와주는 방법들을 실습했습니다.\n",
        "- Grid Search\n",
        "- Random Search\n",
        "- Bayesian\n",
        "- Optuna\n",
        "- Pycaret\n",
        "\n",
        "함께한 모델은 랜덤포레스트와 LGBM입니다."
      ],
      "metadata": {
        "id": "8io7rvt_tGSE"
      },
      "id": "8io7rvt_tGSE"
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn.metrics as metrics\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier \n",
        "from lightgbm import LGBMClassifier"
      ],
      "metadata": {
        "id": "7Ls2jeacAGBB"
      },
      "id": "7Ls2jeacAGBB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### RF\n",
        "저희는 모델링에서 랜덤포레스트의 초매개변수를 설정하지 않은 모델을 학습했습니다.\n",
        "\n",
        "초매개변수 최적화를 위해 랜덤포레스트의 주요 변수를 알아보겠습니다. (과적합 조절은 대게 과소적합 조절을 포함합니다.)\n",
        "\n",
        "랜덤포레스트는 트리기반의 앙상블 분류 모델입니다.\n",
        "- 의사결정나무의 구조: 뿌리에서 잎까지 **아래로** 향하는 구조입니다.\n",
        "- 뿌리(root) -> 분할노드(split node, decision node) -> 잎사귀노드(leaf node)\n",
        "\n",
        "<br/>\n",
        "\n",
        "#### 주요 하이퍼 파라미터\n",
        "\n",
        "#### 1. criterion ({'gini','entropy','log_loss, default='gini'}\n",
        "\n",
        "모델의 분류평가지표를 설정하는 변수이며, 특정 알고리즘을 기준으로 분류를 실시합니다.\n",
        "\n",
        "<br/>\n",
        "\n",
        "#### 2. n_estimators (int, default: 100) -> 성능 및 시간 조절\n",
        "\n",
        "n_estimators는 트리의 개수를 조절하는 변수입니다.\n",
        "\n",
        "분류모델의 개수가 과도하게 적거나 많다면 문제가 발생합니다.\n",
        "\n",
        "<br/>\n",
        "\n",
        "#### 3. max_depth (int, default= None) -> 과적합 조절\n",
        "\n",
        "깊이를 조절할 수 있는 변수입니다.\n",
        "\n",
        "트리기반 분류모델은 위(root)에서 아래(leaf)으로 \"분류의 진행상태\"를 깊이(depth)라고 표현합니다.\n",
        "\n",
        "특정(잘못된) 방향으로 부족하게 또는 과하게 진행되었다면 문제가 발생합니다. \n",
        "\n",
        "<br/>\n",
        "\n",
        "#### 4. min_samples_split (int or float, default= 2) -> 과적합 조절\n",
        "\n",
        "노드를 분할하는 최소한의 샘플 데이터 수입니다.\n",
        "\n",
        "아직 분류되지 않은 샘플이 지정된 개수 이상의 데이터가 남았다면 분류를 하는 것이죠! \n",
        "\n",
        "과도하게 쪼개다보면 과적합이 발생합니다. \n",
        "\n",
        "<br/>\n",
        "\n",
        "#### 5. min_samples_leaf (int or float, default= 1) -> 과적합 조절\n",
        "\n",
        "\n",
        "min_sample_split과 함께 과적합을 조절할 수있지만, 조금 다릅니다. \n",
        "\n",
        "min_sample_split의 경우 split 전에 확인하는 것이고,\n",
        "min_sample_leaf의 경우 split 후에 확인할 수 있는 것입니다. \n",
        "\n",
        "그러므로 하나의 잎으로 분류된 객체가 설정된 개수(min_sample_leaf)보다 적다면 분류가 되지 않는 것으로 과적합을 조절합니다.  \n",
        "\n",
        "<br/>\n",
        "\n",
        "#### 6. max_features ({'sqrt', 'log2', None}, default= \"sqrt\")\n",
        "\n",
        "최적의 분류를 위한 feature의 개수를 산출하는 식을 조절하는 변수입니다.\n",
        "\n",
        "자세한 사항은 아래 공식문서를 참고해주세요.\n",
        "\n",
        "<br/>\n",
        " \n",
        "#### 7. max_leaf_nodes (default= None) -> 과적합 조절\n",
        "\n",
        "잎사귀노드의 최대 개수입니다.\n",
        "\n",
        "잎사귀노드의 수가 부족하거나 과하다면 문제가 발생합니다. \n",
        "\n",
        "<br/>\n",
        "\n",
        "---\n",
        "참고문헌: \n",
        "\n",
        "- Scikit-learn의 RandomForest 공식문서입니다.\n",
        "\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n",
        "\n"
      ],
      "metadata": {
        "id": "S_A7QvtqtbGz"
      },
      "id": "S_A7QvtqtbGz"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### LGBM\n",
        "저희는 모델링과정에서 Light GBM 또한 튜닝없이 진행했습니다. \n",
        "\n",
        "LGBM은 큰 데이터셋에 활용도가 높습니다. 특히 학습시간을 정말 많이 단축시킬 수 있습니다!\n",
        "\n",
        "<br/>\n",
        "\n",
        "주요 하이퍼파라미터\n",
        "#### 1. learning_rate (double, default=0.1)\n",
        "\n",
        "학습률입니다. gradient descent의 학습량을 조절합니다.\n",
        "\n",
        "<br/>\n",
        "\n",
        "#### 2. max_depth (int, default=-1)\n",
        "\n",
        "<= 0 means no limit\n",
        "\n",
        "랜덤포레스트와 동일합니다.\n",
        "\n",
        "<br/>\n",
        "\n",
        "#### 3. num_iterations (int, default=100)\n",
        "\n",
        "랜덤포레스트의 n_estimators와 동일합니다.\n",
        "\n",
        "<br/>\n",
        "\n",
        "#### 4. boosting ({'gbdt','rf','dart'}, default='gbdt')\n",
        "\n",
        "부스팅 방법입니다.\n",
        "\n",
        "'gbdt'는 GBM입니다. 'rf'는 랜덤포레스트입니다. 'dart'는 dropout을 이용한 앙상블모델입니다.\n",
        "\n",
        "dart의 경우 다른 분류기보다 높은 정확도를 형성한다고 알려져있습니다.\n",
        "\n",
        "추가적인 정보는 dart의 논문을 참고해주세요. (참고문헌 확인)\n",
        "\n",
        "<br/>\n",
        "\n",
        "#### 5. metrics\n",
        "\n",
        "학습 목적에 따른 평가지표입니다.\n",
        "\n",
        "binary(cross entropy), muticlass(cross entrop), regression_l1(mae), regression_l2(mse), mape(mape)를 포함하여 여러 지표를 지원합니다. \n",
        "\n",
        "자세한 사항은 아래 공식문서를 참고해주세요.\n",
        "\n",
        "<br/>\n",
        "\n",
        "#### 6. early_stopping_round (int, default=0)\n",
        "\n",
        "<= 0 means disable\n",
        "\n",
        "정확도가 더이상 향상되지 않을 때 조기에 멈추게 되는 반복횟수를 지정합니다. \n",
        "\n",
        "<br/>\n",
        "\n",
        "#### 7.  bagging_fraction (float, default=1.0)\n",
        "\n",
        "행단위로 샘플링합니다. 과적합을 방지할 수 있습니다.\n",
        "\n",
        "<br/>\n",
        "\n",
        "#### 8. feature_fraction (float, default=1.0)\n",
        "\n",
        "열단위로 샘플링합니다. 과적합을 방지할 수 있습니다.\n",
        "\n",
        "<br/>\n",
        "\n",
        "#### 9. scale_pos_weight ()\n",
        "\n",
        "불균형 데이터의 postive의 가중치를 높혀준다. 민감한 파라미터입니다! 불균형 데이터에 효과적입니다.\n",
        "\n",
        "<br/>\n",
        "\n",
        "---\n",
        "\n",
        "참고문헌:\n",
        "\n",
        "- LightGBM의 공식문서입니다.\n",
        "\n",
        "https://lightgbm.readthedocs.io/en/latest/Parameters-Tuning.html\n",
        "\n",
        "- DART의 논문입니다.\n",
        "\n",
        "Vinayak, R. K., & Gilad-Bachrach, R. (2015, February). Dart: Dropouts meet multiple additive regression trees. In Artificial Intelligence and Statistics (pp. 489-497). PMLR."
      ],
      "metadata": {
        "id": "PDjB1TkPu91S"
      },
      "id": "PDjB1TkPu91S"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 튜닝 방법"
      ],
      "metadata": {
        "id": "koE0r6TLt6-3"
      },
      "id": "koE0r6TLt6-3"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Grid Search\n",
        "\n",
        "그리드서치는 초매개변수 최적화의 가장 기본적인 방법입니다.\n",
        "\n",
        "학습 전에 지정한 초매개변수의 집합들을 모두 시행하여 가장 우수한 초매개변수 집합을 얻습니다.\n",
        "\n",
        "<br/>\n",
        "\n",
        "---\n",
        "참고문헌:\n",
        "\n",
        "- Sklearn의 GridSearchCv 공식문서입니다.\n",
        "\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html\n",
        "\n",
        "- scoring에 관한 공식문서입니다.\n",
        "\n",
        "https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter"
      ],
      "metadata": {
        "id": "4wc57b11tlc8"
      },
      "id": "4wc57b11tlc8"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
        "from sklearn.metrics import make_scorer"
      ],
      "metadata": {
        "id": "oOCPt9W1tj_r"
      },
      "id": "oOCPt9W1tj_r",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rf = RandomForestClassifier()\n",
        "\n",
        "param_grid = {\n",
        "    'criterion': ['gini', 'entropy'],\n",
        "    'max_depth': [2, 4, 6, 8, None],\n",
        "    'max_features': ['sqrt','log2'],\n",
        "    'n_estimators': [10, 30, 70, 100]\n",
        "}"
      ],
      "metadata": {
        "id": "akR8X3uiNndd"
      },
      "id": "akR8X3uiNndd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grid_search = GridSearchCV(\n",
        "    estimator=rf, # model\n",
        "    param_grid=param_grid, # set the grid\n",
        "    scoring=make_scorer(accuracy_score), # 평가지표, 추가정보 -> 참고문헌확인\n",
        "    cv=10, # STAGE 6 cross validation\n",
        ")\n",
        "grid_search.fit(train_x, train_y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wqVt__jyPY00",
        "outputId": "1d6c7cdc-dde4-4b7e-fe47-4c9987b77644"
      },
      "id": "wqVt__jyPY00",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=10, error_score=nan,\n",
              "             estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
              "                                              class_weight=None,\n",
              "                                              criterion='gini', max_depth=None,\n",
              "                                              max_features='auto',\n",
              "                                              max_leaf_nodes=None,\n",
              "                                              max_samples=None,\n",
              "                                              min_impurity_decrease=0.0,\n",
              "                                              min_impurity_split=None,\n",
              "                                              min_samples_leaf=1,\n",
              "                                              min_samples_split=2,\n",
              "                                              min_weight_fraction_leaf=0.0,\n",
              "                                              n_estimators=100, n_jobs=None,\n",
              "                                              oob_score=False,\n",
              "                                              random_state=None, verbose=0,\n",
              "                                              warm_start=False),\n",
              "             iid='deprecated', n_jobs=None,\n",
              "             param_grid={'criterion': ['gini', 'entropy'],\n",
              "                         'max_depth': [2, 4, 6, 8, None],\n",
              "                         'max_features': ['sqrt', 'log2'],\n",
              "                         'n_estimators': [10, 30, 70, 100]},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring=make_scorer(accuracy_score), verbose=0)"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "grid_search.predict(valid_x)\n",
        "grid_search_pred = grid_search.predict_proba(valid_x)"
      ],
      "metadata": {
        "id": "7hNyZKLIPYy3"
      },
      "id": "7hNyZKLIPYy3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Best parameters found: \", grid_search.best_params_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xg7m9jkDNnbb",
        "outputId": "b2f61a55-5ba3-4364-e399-f2fe5cbef681"
      },
      "id": "xg7m9jkDNnbb",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters found:  {'criterion': 'gini', 'max_depth': 4, 'max_features': 'log2', 'n_estimators': 10}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'정확도: {accuracy_score(valid_y, grid_search.predict(valid_x)) * 100:.4f}%')\n",
        "print(f'재현율: {recall_score(valid_y, grid_search.predict(valid_x),pos_label=1) * 100:.4f}%')\n",
        "print(f'F1_score: {f1_score(valid_y, grid_search.predict(valid_x)) * 100:.4f}%')\n",
        "print(f'ROC_AUC: {roc_auc_score(valid_y, grid_search.predict(valid_x)) * 100:.4f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZAWyX3PYPX7c",
        "outputId": "c3b6cc3e-47d5-4be5-8227-22d690a7c8b9"
      },
      "id": "ZAWyX3PYPX7c",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "정확도: 94.4444%\n",
            "재현율: 100.0000%\n",
            "F1_score: 97.1429%\n",
            "ROC_AUC: 50.0000%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Random Search\n",
        "\n",
        "랜덤서치는 지정된 범위 내에서 무작위로 초매개변수를 조합하여 최적화를 시도합니다.\n",
        "\n",
        "<br/>\n",
        "\n",
        "\n",
        "장단점은 **무작위**하다는 점입니다. \n",
        "\n",
        "경우에 따라 그리드서치에 비해 빠르고 느릴 수 있습니다. \n",
        "\n",
        "또한 성과를 가늠할 수 없기때문에 생각치 못한 결과를 맞이할 수 있습니다. \n",
        "\n",
        "그렇기 때문에 최적화 보다 성과의 방향성을 살펴보기 위해 주로 시도합니다.\n",
        "\n",
        "<br/>\n",
        "\n",
        "---\n",
        "참고문헌:\n",
        "\n",
        "\"랜덤서치가 그리드서치보다 효율적임\"을 주장하는 논문도 있습니다. \n",
        "\n",
        "[Bergstra, J., & Bengio, Y. (2012). Random search for hyper-parameter optimization. Journal of machine learning research, 13(2).](https://www.jmlr.org/papers/volume13/bergstra12a/bergstra12a.pdf)"
      ],
      "metadata": {
        "id": "HzAUNzCEtoTL"
      },
      "id": "HzAUNzCEtoTL"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV"
      ],
      "metadata": {
        "id": "8rhPPDis5vZk"
      },
      "id": "8rhPPDis5vZk",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = RandomForestClassifier()\n",
        "\n",
        "param_distributions = {\n",
        "    'criterion': ['gini', 'entropy'],\n",
        "    'max_depth': [2, 4, 6, 8, None],\n",
        "    'max_features': ['sqrt','log2'],\n",
        "    'n_estimators': [10, 30, 70, 100]\n",
        "}\n",
        "randomized_search = RandomizedSearchCV(model, \n",
        "                                       param_distributions=param_distributions, \n",
        "                                       n_iter=50, cv=10, # STAGE 6 cross validation\n",
        "                                       scoring='accuracy', return_train_score=True,\n",
        "                                       verbose=1,\n",
        "                                       random_state=random_state)\n",
        "\n",
        "randomized_search.fit(train_x, train_y)\n",
        "\n",
        "df = pd.DataFrame(randomized_search.cv_results_).sort_values(by=['mean_test_score', 'mean_train_score'], ascending=False)\n",
        "display(df[['params', 'mean_train_score', 'mean_test_score']].head(10))"
      ],
      "metadata": {
        "id": "WNURN223tj9h",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        },
        "outputId": "b9d4b192-d753-468e-b3f3-74c120be3f6d"
      },
      "id": "WNURN223tj9h",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 10 folds for each of 50 candidates, totalling 500 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:  1.1min finished\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                               params  mean_train_score  \\\n",
              "1   {'n_estimators': 100, 'max_features': 'sqrt', ...               1.0   \n",
              "2   {'n_estimators': 70, 'max_features': 'log2', '...               1.0   \n",
              "5   {'n_estimators': 100, 'max_features': 'log2', ...               1.0   \n",
              "6   {'n_estimators': 70, 'max_features': 'sqrt', '...               1.0   \n",
              "15  {'n_estimators': 70, 'max_features': 'sqrt', '...               1.0   \n",
              "19  {'n_estimators': 70, 'max_features': 'sqrt', '...               1.0   \n",
              "21  {'n_estimators': 70, 'max_features': 'log2', '...               1.0   \n",
              "23  {'n_estimators': 100, 'max_features': 'log2', ...               1.0   \n",
              "39  {'n_estimators': 100, 'max_features': 'log2', ...               1.0   \n",
              "44  {'n_estimators': 100, 'max_features': 'sqrt', ...               1.0   \n",
              "\n",
              "    mean_test_score  \n",
              "1          0.951905  \n",
              "2          0.951905  \n",
              "5          0.951905  \n",
              "6          0.951905  \n",
              "15         0.951905  \n",
              "19         0.951905  \n",
              "21         0.951905  \n",
              "23         0.951905  \n",
              "39         0.951905  \n",
              "44         0.951905  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bcdd1ce9-b008-404b-846f-b05330161b35\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>params</th>\n",
              "      <th>mean_train_score</th>\n",
              "      <th>mean_test_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>{'n_estimators': 100, 'max_features': 'sqrt', ...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.951905</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>{'n_estimators': 70, 'max_features': 'log2', '...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.951905</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>{'n_estimators': 100, 'max_features': 'log2', ...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.951905</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>{'n_estimators': 70, 'max_features': 'sqrt', '...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.951905</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>{'n_estimators': 70, 'max_features': 'sqrt', '...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.951905</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>{'n_estimators': 70, 'max_features': 'sqrt', '...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.951905</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>{'n_estimators': 70, 'max_features': 'log2', '...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.951905</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>{'n_estimators': 100, 'max_features': 'log2', ...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.951905</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>{'n_estimators': 100, 'max_features': 'log2', ...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.951905</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>{'n_estimators': 100, 'max_features': 'sqrt', ...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.951905</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bcdd1ce9-b008-404b-846f-b05330161b35')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-bcdd1ce9-b008-404b-846f-b05330161b35 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-bcdd1ce9-b008-404b-846f-b05330161b35');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('최적 하이퍼파라미터: ', randomized_search.best_params_)\n",
        "print('학습 검증 정확도:', randomized_search.best_score_)\n",
        "\n",
        "print(f'정확도: {accuracy_score(valid_y, randomized_search.predict(valid_x)) * 100:.4f}%')\n",
        "print(f'재현율: {recall_score(valid_y, randomized_search.predict(valid_x),pos_label=1) * 100:.4f}%')\n",
        "print(f'F1_score: {f1_score(valid_y, randomized_search.predict(valid_x)) * 100:.4f}%')\n",
        "print(f'ROC_AUC: {roc_auc_score(valid_y, randomized_search.predict(valid_x)) * 100:.4f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cchZi4yanx03",
        "outputId": "84a38745-b269-49a0-e0a9-3b19eae2c17a"
      },
      "id": "cchZi4yanx03",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "최적 하이퍼파라미터:  {'n_estimators': 70, 'max_features': 'sqrt', 'max_depth': 4, 'criterion': 'entropy'}\n",
            "학습 검증 정확도: 0.9519047619047617\n",
            "정확도: 94.4444%\n",
            "재현율: 100.0000%\n",
            "F1_score: 97.1429%\n",
            "ROC_AUC: 50.0000%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Bayesian Optimization\n",
        "\n",
        "**베이지안 추론**이란?\n",
        "\n",
        "베이지안 추론(Bayesian inference)은 통계적 추론으로, 사건에 대한 사전(prior)확률과 추가적인 정보에의한 사건에 대한 사후(posterior)확률을 입니다.\n",
        "\n",
        "<br/>\n",
        "\n",
        "**베이지안 최적화**란?\n",
        "\n",
        "사전 정보를 최적 값 탐색에 반영하는 것이라고 이해할 수 있습니다.\n",
        "\n",
        "함수f(x)을 최대로 만드는 최적해를 찾는 것을 목적으로 하는 최적화 방법입니다.\n",
        "\n",
        "베이지안 최적화 모델은 Surrogate Model(대체 모델, 근사수학모델, ), Acquisition Function의 두가지 요소가 반드시 필요합니다.\n",
        "\n",
        "<br/>\n",
        "\n",
        "\n",
        "**Surrogate Model**이란? \n",
        "\n",
        "뜻은 대체모델 또는 근사수학모델입니다. 복잡한 시스템의 수많은 입출력 특성으로 실제 모형과 유사하게 만드는 모델입니다. \n",
        "\n",
        "베이지안 최적화 모델은 확률적인 추정을 통해 최적화를 시도합니다.\n",
        "\n",
        "예를 들면, 자동차 충돌실험모델 등이 있습니다.\n",
        "\n",
        "<br/>\n",
        "\n",
        "**Acquisition Function** 이란? \n",
        "\n",
        "최적해를 찾는 과정에서 가장 유용할 다음 입력값의 후보를 추천해 주는 함수입니다.\n",
        "\n",
        "수학적으로 목적함수에 대해서 확률적 추정을 통한 모델을 기반으로 다음 탐색지점을 결정합니다.\n",
        "\n",
        "이때 정보량이 많은 곳을 우선적으로 추천하게 됩니다.\n",
        "\n",
        "요약하면 최적의 값을 추천하는 함수입니다.\n",
        "\n",
        "<br/>\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "참고문헌:\n",
        "\n",
        "Bayesina optimization의 github입니다.\n",
        "\n",
        "https://github.com/fmfn/BayesianOptimization"
      ],
      "metadata": {
        "id": "rBVPok_6tqXs"
      },
      "id": "rBVPok_6tqXs"
    },
    {
      "cell_type": "code",
      "source": [
        "# pip install bayesian-optimization"
      ],
      "metadata": {
        "id": "748jgnhAtj7T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b413609-6ab5-4802-e1ff-bfb7f0bea26e"
      },
      "id": "748jgnhAtj7T",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting bayesian-optimization\n",
            "  Downloading bayesian_optimization-1.4.2-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.8/dist-packages (from bayesian-optimization) (1.21.6)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from bayesian-optimization) (1.7.3)\n",
            "Collecting colorama>=0.4.6\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: scikit-learn>=0.18.0 in /usr/local/lib/python3.8/dist-packages (from bayesian-optimization) (1.0.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.18.0->bayesian-optimization) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.18.0->bayesian-optimization) (3.1.0)\n",
            "Installing collected packages: colorama, bayesian-optimization\n",
            "Successfully installed bayesian-optimization-1.4.2 colorama-0.4.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from bayes_opt import BayesianOptimization"
      ],
      "metadata": {
        "id": "cwBlyDE6MV4v"
      },
      "id": "cwBlyDE6MV4v",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def lgbm_evaluate(learning_rate, max_depth, n_estimators, bagging_fraction, feature_fraction, scale_pos_weight):\n",
        "    model = LGBMClassifier(random_state=random_state,\n",
        "                           objective='binary',\n",
        "                           metric='binary_logloss',\n",
        "                           learning_rate=learning_rate,\n",
        "                           max_depth=int(max_depth),\n",
        "                           n_estimators=int(n_estimators),\n",
        "                           bagging_fraction=float(bagging_fraction),\n",
        "                           feature_fraction=float(feature_fraction),\n",
        "                           scale_pos_weight=float(scale_pos_weight)\n",
        "    )\n",
        "    accuracy = np.mean(cross_val_score(model, train_x, train_y, cv=10, scoring=make_scorer(accuracy_score))) # STAGE 6 cross validation\n",
        "\n",
        "    return accuracy"
      ],
      "metadata": {
        "id": "k-qG5kjBMV3I"
      },
      "id": "k-qG5kjBMV3I",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tuned_lgbm = BayesianOptimization(lgbm_evaluate, \n",
        "                                  {\"learning_rate\": (0.001, 0.1),\n",
        "                                   \"max_depth\": (-1, 20),\n",
        "                                   \"n_estimators\": (100,10000),\n",
        "                                   \"bagging_fraction\": (0.3, 0.7),\n",
        "                                   \"feature_fraction\": (0.3, 0.7),\n",
        "                                   \"scale_pos_weight\": (0.01, 0.15)\n",
        "})\n",
        "\n",
        "tuned_lgbm.maximize(init_points=5, n_iter=10, acq='ei',) # init_points: 임의탐색횟수, n_iter: 주변 탐색, acq: 제공하는 함수 선택"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yels55JXMf8d",
        "outputId": "1af8b779-16d1-4cf9-88e6-33a683dfdb05"
      },
      "id": "Yels55JXMf8d",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "|   iter    |  target   | baggin... | featur... | learni... | max_depth | n_esti... | scale_... |\n",
            "-------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-242-5af6982f19ef>:10: DeprecationWarning: \n",
            "Passing acquisition function parameters or gaussian process parameters to maximize\n",
            "is no longer supported, and will cause an error in future releases. Instead,\n",
            "please use the \"set_gp_params\" method to set the gp params, and pass an instance\n",
            " of bayes_opt.util.UtilityFunction using the acquisition_function argument\n",
            "\n",
            "  tuned_lgbm.maximize(init_points=5, n_iter=10, acq='ei',) # init_points: 임의탐색횟수, n_iter: 주변 탐색, acq: 제공하는 함수 선택\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| \u001b[0m1        \u001b[0m | \u001b[0m0.9329   \u001b[0m | \u001b[0m0.6802   \u001b[0m | \u001b[0m0.4813   \u001b[0m | \u001b[0m0.008052 \u001b[0m | \u001b[0m-0.9236  \u001b[0m | \u001b[0m4.964e+03\u001b[0m | \u001b[0m0.1414   \u001b[0m |\n",
            "| \u001b[95m2        \u001b[0m | \u001b[95m0.9376   \u001b[0m | \u001b[95m0.5889   \u001b[0m | \u001b[95m0.5726   \u001b[0m | \u001b[95m0.0485   \u001b[0m | \u001b[95m19.33    \u001b[0m | \u001b[95m6.567e+03\u001b[0m | \u001b[95m0.1038   \u001b[0m |\n",
            "| \u001b[0m3        \u001b[0m | \u001b[0m0.9376   \u001b[0m | \u001b[0m0.5659   \u001b[0m | \u001b[0m0.3453   \u001b[0m | \u001b[0m0.04337  \u001b[0m | \u001b[0m14.71    \u001b[0m | \u001b[0m2.103e+03\u001b[0m | \u001b[0m0.05452  \u001b[0m |\n",
            "| \u001b[0m4        \u001b[0m | \u001b[0m0.9233   \u001b[0m | \u001b[0m0.6015   \u001b[0m | \u001b[0m0.4268   \u001b[0m | \u001b[0m0.08452  \u001b[0m | \u001b[0m1.25     \u001b[0m | \u001b[0m872.2    \u001b[0m | \u001b[0m0.1222   \u001b[0m |\n",
            "| \u001b[0m5        \u001b[0m | \u001b[0m0.9329   \u001b[0m | \u001b[0m0.3913   \u001b[0m | \u001b[0m0.4691   \u001b[0m | \u001b[0m0.03177  \u001b[0m | \u001b[0m17.7     \u001b[0m | \u001b[0m6.472e+03\u001b[0m | \u001b[0m0.1162   \u001b[0m |\n",
            "| \u001b[0m6        \u001b[0m | \u001b[0m0.9329   \u001b[0m | \u001b[0m0.4903   \u001b[0m | \u001b[0m0.3869   \u001b[0m | \u001b[0m0.05464  \u001b[0m | \u001b[0m15.74    \u001b[0m | \u001b[0m6.672e+03\u001b[0m | \u001b[0m0.05081  \u001b[0m |\n",
            "| \u001b[0m7        \u001b[0m | \u001b[0m0.9329   \u001b[0m | \u001b[0m0.5574   \u001b[0m | \u001b[0m0.5061   \u001b[0m | \u001b[0m0.01281  \u001b[0m | \u001b[0m16.01    \u001b[0m | \u001b[0m2.102e+03\u001b[0m | \u001b[0m0.05561  \u001b[0m |\n",
            "| \u001b[0m8        \u001b[0m | \u001b[0m0.9376   \u001b[0m | \u001b[0m0.636    \u001b[0m | \u001b[0m0.6487   \u001b[0m | \u001b[0m0.05558  \u001b[0m | \u001b[0m18.51    \u001b[0m | \u001b[0m8.477e+03\u001b[0m | \u001b[0m0.05636  \u001b[0m |\n",
            "| \u001b[0m9        \u001b[0m | \u001b[0m0.9329   \u001b[0m | \u001b[0m0.6903   \u001b[0m | \u001b[0m0.5604   \u001b[0m | \u001b[0m0.07796  \u001b[0m | \u001b[0m4.237    \u001b[0m | \u001b[0m3.375e+03\u001b[0m | \u001b[0m0.01645  \u001b[0m |\n",
            "| \u001b[0m10       \u001b[0m | \u001b[0m0.9281   \u001b[0m | \u001b[0m0.5736   \u001b[0m | \u001b[0m0.5983   \u001b[0m | \u001b[0m0.07075  \u001b[0m | \u001b[0m0.3786   \u001b[0m | \u001b[0m590.7    \u001b[0m | \u001b[0m0.07174  \u001b[0m |\n",
            "| \u001b[0m11       \u001b[0m | \u001b[0m0.9329   \u001b[0m | \u001b[0m0.5761   \u001b[0m | \u001b[0m0.3017   \u001b[0m | \u001b[0m0.04471  \u001b[0m | \u001b[0m15.53    \u001b[0m | \u001b[0m3.781e+03\u001b[0m | \u001b[0m0.08687  \u001b[0m |\n",
            "| \u001b[0m12       \u001b[0m | \u001b[0m0.9281   \u001b[0m | \u001b[0m0.5917   \u001b[0m | \u001b[0m0.484    \u001b[0m | \u001b[0m0.05237  \u001b[0m | \u001b[0m6.744    \u001b[0m | \u001b[0m9.909e+03\u001b[0m | \u001b[0m0.02335  \u001b[0m |\n",
            "| \u001b[0m13       \u001b[0m | \u001b[0m0.9329   \u001b[0m | \u001b[0m0.6427   \u001b[0m | \u001b[0m0.4957   \u001b[0m | \u001b[0m0.04696  \u001b[0m | \u001b[0m17.46    \u001b[0m | \u001b[0m8.478e+03\u001b[0m | \u001b[0m0.0825   \u001b[0m |\n",
            "| \u001b[0m14       \u001b[0m | \u001b[0m0.9329   \u001b[0m | \u001b[0m0.5033   \u001b[0m | \u001b[0m0.657    \u001b[0m | \u001b[0m0.06361  \u001b[0m | \u001b[0m14.4     \u001b[0m | \u001b[0m2.102e+03\u001b[0m | \u001b[0m0.02536  \u001b[0m |\n",
            "| \u001b[0m15       \u001b[0m | \u001b[0m0.9329   \u001b[0m | \u001b[0m0.4016   \u001b[0m | \u001b[0m0.6114   \u001b[0m | \u001b[0m0.0383   \u001b[0m | \u001b[0m18.17    \u001b[0m | \u001b[0m6.566e+03\u001b[0m | \u001b[0m0.06807  \u001b[0m |\n",
            "=================================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tuned_lgbm.max['params']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iGfMSFLDMf6l",
        "outputId": "e3be3ad2-94ea-4dba-a286-31f0b507e7b5"
      },
      "id": "iGfMSFLDMf6l",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'bagging_fraction': 0.5889330482450694,\n",
              " 'feature_fraction': 0.5725915935375597,\n",
              " 'learning_rate': 0.048499029875590356,\n",
              " 'max_depth': 19.325383056784766,\n",
              " 'n_estimators': 6566.964373017123,\n",
              " 'scale_pos_weight': 0.10381324415995875}"
            ]
          },
          "metadata": {},
          "execution_count": 247
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Optuna\n",
        "\n",
        "Optuna는 초매개변수 최적화 프레임워크 입니다.\n",
        "\n",
        "optuna는 가볍고 효율적으로 초매개변수 최적화를 지원합니다. 또한 함수식이 직관적이며 시각화도 편리합니다.\n",
        "\n",
        "<br/>\n",
        "\n",
        "옵튜나는 두 단어(study, trial)를 사용합니다.\n",
        "\n",
        "**Study**란?\n",
        "\n",
        "objective function에 기반한 일련의 최적화 과정입니다.\n",
        "\n",
        "<br/>\n",
        "\n",
        "**Trial**란?\n",
        "\n",
        "objective function의 1번의 시행\n",
        "\n",
        "study의 목표는 n번의 trial를 통해 최적의 초매개변수 조합을 찾는 것입니다.\n",
        "\n",
        "<br/>\n",
        "\n",
        "---\n",
        "참고문헌:\n",
        "- 자세한 사항은 아래 Oputna의 Github를 참고해주세요.\n",
        "\n",
        "https://github.com/optuna/optuna \n",
        "\n",
        "- 아래는 optuna의 예시 목록입니다.\n",
        "\n",
        "https://github.com/optuna/optuna-examples"
      ],
      "metadata": {
        "id": "6mDnVdPMtq7S"
      },
      "id": "6mDnVdPMtq7S"
    },
    {
      "cell_type": "code",
      "source": [
        "# optuna 설치하는 방법\n",
        "# pip install optuna"
      ],
      "metadata": {
        "id": "uafcmRtQ5oXQ"
      },
      "id": "uafcmRtQ5oXQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import optuna\n",
        "from optuna import Trial\n",
        "from optuna.samplers import TPESampler # oputna의 시행방법은 TPESampler, SKoptsampler 등이 있다."
      ],
      "metadata": {
        "id": "OOeSHWp-5o1M"
      },
      "id": "OOeSHWp-5o1M",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def objective(trial: Trial) -> float: # 목적함수를 정의한다.\n",
        "    global train_x, train_y, valid_x, valid_y\n",
        "    params_lgb = {\n",
        "        \"random_state\": 0,\n",
        "        \"verbosity\": -1,\n",
        "        \"objective\": \"binary\", # 종속변수 = open, close\n",
        "        \"metric\": \"binary_logloss\",\n",
        "        \n",
        "        \"learning_rate\": trial.suggest_float(\"reg_alpha\", 0.001, 0.1),\n",
        "        \"max_depth\": trial.suggest_int(\"max_depth\", 1, 20),\n",
        "        \"n_estimators\": 10000,\n",
        "        \"bagging_fraction\": trial.suggest_float(\"bagging_fraction\", 0.3, 0.7),\n",
        "        \"feature_fraction\": trial.suggest_float(\"feature_fraction\", 0.3, 0.7),\n",
        "        \"scale_pos_weight\": trial.suggest_float(\"scale_pos_weight\", 0.01, 0.15),\n",
        "    }\n",
        "    model = LGBMClassifier(**params_lgb) # params_lgb에 입력한 함수를 모두 받아온다. \"**\"는 입력값을 길이제한 없이 받아온다.\n",
        "    model.fit(train_x,train_y,\n",
        "        eval_set=[(train_x, train_y), (valid_x, valid_y)],\n",
        "        early_stopping_rounds=500, # early_stopping은 500번으로 제한했다.\n",
        "        verbose=True, # 진행사항 on/off\n",
        "    )\n",
        "    lgb_pred = model.predict_proba(valid_x)\n",
        "    log_score = log_loss(valid_y, lgb_pred) # log_loss를 사용한다.\n",
        "    return log_score "
      ],
      "metadata": {
        "id": "ZDfOXBzWtrOU"
      },
      "id": "ZDfOXBzWtrOU",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sampler = TPESampler(seed=0)\n",
        "study = optuna.create_study(\n",
        "    study_name=\"lgbm_parameter_opt\",\n",
        "    direction=\"minimize\", # 목적함수의 return은 log_score이다. 즉, log_loss를 최소화하는 study\n",
        "    sampler=sampler,      # 만일 accuracy라든지 roc-auc 같이 값이 커져야 하는 경우는 maximize로 설정해야 합니다.\n",
        ")                         \n",
        "study.optimize(objective, n_trials=100,) # trial을 100번 시행\n",
        "print(\"Best Score:\", study.best_value) # 최상의 성적을 가져온다.\n",
        "print(\"Best trial:\", study.best_trial.params) # 최상의 컨디션을 가진 변수집합을 가져온다."
      ],
      "metadata": {
        "id": "JJZCE10s3Lv0"
      },
      "id": "JJZCE10s3Lv0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lgbm(base)\n",
        "lgbm = LGBMClassifier(random_state=random_state)\n",
        "lgbm.fit(train_x, train_y)\n",
        "# tuned Lgbm\n",
        "tuned_lgbm = LGBMClassifier(**study.best_trial.params) # 튜닝된 하이퍼파라미터를 받아온다.\n",
        "tuned_lgbm.fit(train_x, train_y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1_OQlmcK3LtK",
        "outputId": "0e55b53a-2954-464a-c3a8-7d1d549963fc"
      },
      "id": "1_OQlmcK3LtK",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LGBMClassifier(bagging_fraction=0.6503981375433736,\n",
              "               feature_fraction=0.6196769255303484, max_depth=4,\n",
              "               reg_alpha=0.01940607436602854,\n",
              "               scale_pos_weight=0.11936722683048441)"
            ]
          },
          "metadata": {},
          "execution_count": 254
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for model, name in zip([lgbm, tuned_lgbm], ['lgbm','tuned_lgbm']):\n",
        "    print('##########',name,'##########')\n",
        "    print(f'정밀도: {metrics.precision_score(valid_y, model.predict(valid_x)) * 100:.4f}%')\n",
        "    print(f'재현율: {recall_score(valid_y, model.predict(valid_x),pos_label=1) * 100:.4f}%')\n",
        "    print(f'f1_score: {f1_score(valid_y, model.predict(valid_x)) * 100:.4f}%')\n",
        "    print(f'정확도: {accuracy_score(valid_y, model.predict(valid_x)) * 100:.4f}%')\n",
        "    print(f'ROC_AUC: {roc_auc_score(valid_y, model.predict(valid_x)) * 100:.4f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qx4xGFdj3Lpw",
        "outputId": "b76fe7db-7e75-44bf-9675-823c34348afb"
      },
      "id": "Qx4xGFdj3Lpw",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "########## lgbm ##########\n",
            "정밀도: 94.3820%\n",
            "재현율: 98.8235%\n",
            "f1_score: 96.5517%\n",
            "정확도: 93.3333%\n",
            "ROC_AUC: 49.4118%\n",
            "########## tuned_lgbm ##########\n",
            "정밀도: 94.3820%\n",
            "재현율: 98.8235%\n",
            "f1_score: 96.5517%\n",
            "정확도: 93.3333%\n",
            "ROC_AUC: 49.4118%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "😥 안타깝지만, 역시나 튜닝의 결과와 기본모델와 같네요.. \n",
        "\n",
        "더 큰 데이터셋을 이용하시길 바랍니다!"
      ],
      "metadata": {
        "id": "PpRhORBJ8Ds0"
      },
      "id": "PpRhORBJ8Ds0"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### AutoML by pycaret"
      ],
      "metadata": {
        "id": "g5Howgdetri6"
      },
      "id": "g5Howgdetri6"
    },
    {
      "cell_type": "code",
      "source": [
        "lightgbm = create_model('lightgbm')\n",
        "tuned_lightgbm = tune_model(lightgbm)\n",
        "rf = create_model('rf')\n",
        "tuned_rf = tune_model(rf)"
      ],
      "metadata": {
        "id": "hj-nStzTtyV7"
      },
      "id": "hj-nStzTtyV7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 마무리"
      ],
      "metadata": {
        "id": "1RvocbMvN0Mx"
      },
      "id": "1RvocbMvN0Mx"
    },
    {
      "cell_type": "markdown",
      "source": [
        "이번 Stage에서 배운 다양한 방법을 활용하여 데이터를 전처리하는 방법은 다른 대회에서도 유용하게 응용할 수 있을 것입니다.\n",
        "\n",
        "따라서 ‘병원 개/폐업 분류 예측 경진대회🏥’뿐만 아니라 다른 주제의 대회에서도 이번 stage가 큰 도움이 될 것이라 기대합니다. 😉\n",
        "\n",
        "데이커 여러분 잘 따라오셨나요. 그럼 다음 stage에서 뵙겠습니다.. 🎉"
      ],
      "metadata": {
        "id": "TrI7u-6iN2OB"
      },
      "id": "TrI7u-6iN2OB"
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}